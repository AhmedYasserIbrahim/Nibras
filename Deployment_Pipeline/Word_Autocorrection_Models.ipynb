{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Language Model Benchmar for Word Autocorrection\n",
        "\n",
        "In this section, we build an **Autocorrection Model** that can be used to\n",
        "reconstruct words from noisy letter predictions (like EEG outputs).\n",
        "This LM assigns probabilities to sequences of characters, helping us\n",
        "choose the most likely word given partial or uncertain inputs.\n",
        "\n"
      ],
      "metadata": {
        "id": "hFgLCa5RCjaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autocorrect (Python library)**\n",
        "\n",
        "The autocorrect library implements a fast, word-level spell corrector popularized by Peter Norvig’s approach, using word frequencies to suggest likely corrections. It’s lightweight (pure Python), easy to set up, and well-suited for real-time use where you need quick, per-word fixes without heavy context modeling."
      ],
      "metadata": {
        "id": "_zdxdVRE8VMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Autocorrect: end-to-end word-based autocorrection with timing ===\n",
        "# This cell:\n",
        "# 1) Ensures the autocorrect package is installed\n",
        "# 2) Lets you input a sentence\n",
        "# 3) Returns the autocorrected sentence (word-based)\n",
        "# 4) Prints the time taken for the correction\n",
        "\n",
        "import sys, subprocess, re, time\n",
        "\n",
        "# --- 1) Ensure dependency is installed ---\n",
        "try:\n",
        "    from autocorrect import Speller\n",
        "except Exception:\n",
        "    print(\"Installing 'autocorrect'...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"autocorrect\"])\n",
        "    from autocorrect import Speller\n",
        "\n",
        "# --- 2) Configure the word-level speller ---\n",
        "spell = Speller(lang='en')  # change 'en' if you need another supported language\n",
        "\n",
        "def autocorrect_sentence(sentence: str) -> str:\n",
        "    \"\"\"\n",
        "    Word-based autocorrection that preserves whitespace and punctuation.\n",
        "    Only alphabetic word tokens are corrected to avoid mangling numbers/symbols.\n",
        "    \"\"\"\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]+|\\s+\", sentence)  # words, punctuation, spaces\n",
        "    corrected_parts = []\n",
        "    for tok in tokens:\n",
        "        if tok.isalpha():  # correct only alphabetic tokens\n",
        "            corrected_parts.append(spell(tok))\n",
        "        else:\n",
        "            corrected_parts.append(tok)\n",
        "    return \"\".join(corrected_parts)\n",
        "\n",
        "# --- 3) Get user input, run correction, measure latency ---\n",
        "try:\n",
        "    user_text = input(\"Enter a sentence to autocorrect: \").strip()\n",
        "except EOFError:\n",
        "    # Fallback for environments without stdin\n",
        "    user_text = \"I liek to wrok with pyhton and machne leraning.\"\n",
        "\n",
        "start = time.perf_counter()\n",
        "corrected = autocorrect_sentence(user_text)\n",
        "elapsed_ms = (time.perf_counter() - start) * 1000.0\n",
        "\n",
        "print(\"\\nOriginal : \", user_text)\n",
        "print(\"Corrected: \", corrected)\n",
        "print(f\"Latency  : {elapsed_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2iPV-qB8doN",
        "outputId": "b339d0a3-f938-4f1d-e239-c62f11ddd310"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to autocorrect: how ould are yo\n",
            "\n",
            "Original :  how ould are yo\n",
            "Corrected:  how would are yo\n",
            "Latency  : 0.37 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpellChecker**\n",
        "\n",
        "The pyspellchecker library is a pure Python implementation of Peter Norvig’s algorithm for spell correction. It works by checking words against a frequency dictionary and finding the closest candidates based on edit distance. It’s lightweight, dependency-free, and offers a good balance between accuracy and speed for single-word corrections."
      ],
      "metadata": {
        "id": "K6YbUkmx9AHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PySpellChecker: end-to-end word-based autocorrection with timing ===\n",
        "# This cell:\n",
        "# 1) Ensures the pyspellchecker package is installed\n",
        "# 2) Lets you input a sentence\n",
        "# 3) Returns the autocorrected sentence (word-based)\n",
        "# 4) Prints the time taken for the correction\n",
        "\n",
        "import sys, subprocess, re, time\n",
        "\n",
        "# --- 1) Ensure dependency is installed ---\n",
        "try:\n",
        "    from spellchecker import SpellChecker\n",
        "except Exception:\n",
        "    print(\"Installing 'pyspellchecker'...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pyspellchecker\"])\n",
        "    from spellchecker import SpellChecker\n",
        "\n",
        "# --- 2) Configure the spell checker ---\n",
        "spell = SpellChecker(language='en')  # English by default\n",
        "\n",
        "def autocorrect_sentence(sentence: str) -> str:\n",
        "    \"\"\"\n",
        "    Word-based autocorrection using pyspellchecker.\n",
        "    Preserves whitespace and punctuation.\n",
        "    \"\"\"\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]+|\\s+\", sentence)\n",
        "    corrected_parts = []\n",
        "    for tok in tokens:\n",
        "        if tok.isalpha():\n",
        "            # Correct word if misspelled, else keep original\n",
        "            corrected = spell.correction(tok)\n",
        "            corrected_parts.append(corrected if corrected else tok)\n",
        "        else:\n",
        "            corrected_parts.append(tok)\n",
        "    return \"\".join(corrected_parts)\n",
        "\n",
        "# --- 3) Get user input, run correction, measure latency ---\n",
        "try:\n",
        "    user_text = input(\"Enter a sentence to autocorrect: \").strip()\n",
        "except EOFError:\n",
        "    user_text = \"I liek to wrok with pyhton and machne leraning.\"\n",
        "\n",
        "start = time.perf_counter()\n",
        "corrected = autocorrect_sentence(user_text)\n",
        "elapsed_ms = (time.perf_counter() - start) * 1000.0\n",
        "\n",
        "print(\"\\nOriginal : \", user_text)\n",
        "print(\"Corrected: \", corrected)\n",
        "print(f\"Latency  : {elapsed_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dDSvvWy9DWE",
        "outputId": "5f9513f8-5a04-4778-96bb-d38de61301c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to autocorrect: i am fine thannk yo whar abour yo\n",
            "\n",
            "Original :  i am fine thannk yo whar abour yo\n",
            "Corrected:  i am fine thank yo what about yo\n",
            "Latency  : 2.75 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SymSpell**\n",
        "\n",
        "SymSpell is one of the fastest and most memory-efficient spell correction algorithms. Instead of computing edit distances at runtime, it precomputes and stores all possible word deletions in a dictionary. This allows real-time corrections even on large vocabularies, making it one of the best options for applications where speed and scalability are critical."
      ],
      "metadata": {
        "id": "biuOv6Ei9dYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === SymSpell: end-to-end word-based autocorrection with timing ===\n",
        "# This cell:\n",
        "# 1) Ensures the symspellpy package is installed\n",
        "# 2) Initializes SymSpell with a frequency dictionary\n",
        "# 3) Lets you input a sentence\n",
        "# 4) Returns the autocorrected sentence (word-based)\n",
        "# 5) Prints the time taken for the correction\n",
        "\n",
        "import sys, subprocess, re, time, os\n",
        "\n",
        "# --- 1) Ensure dependency is installed ---\n",
        "try:\n",
        "    from symspellpy import SymSpell, Verbosity\n",
        "except Exception:\n",
        "    print(\"Installing 'symspellpy'...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"symspellpy\"])\n",
        "    from symspellpy import SymSpell, Verbosity\n",
        "\n",
        "# --- 2) Configure SymSpell ---\n",
        "sym_spell = SymSpell()  # initialize with defaults\n",
        "\n",
        "# Download dictionary if not already available\n",
        "dict_path = \"frequency_dictionary_en_82_765.txt\"\n",
        "if not os.path.exists(dict_path):\n",
        "    import urllib.request\n",
        "    print(\"Downloading frequency dictionary...\")\n",
        "    url = \"https://raw.githubusercontent.com/mammothb/symspellpy/master/symspellpy/frequency_dictionary_en_82_765.txt\"\n",
        "    urllib.request.urlretrieve(url, dict_path)\n",
        "\n",
        "# Load dictionary (word -> frequency)\n",
        "sym_spell.load_dictionary(dict_path, term_index=0, count_index=1)\n",
        "\n",
        "def autocorrect_sentence(sentence: str) -> str:\n",
        "    \"\"\"\n",
        "    Word-based autocorrection using SymSpell.\n",
        "    Preserves whitespace and punctuation.\n",
        "    \"\"\"\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]+|\\s+\", sentence)\n",
        "    corrected_parts = []\n",
        "    for tok in tokens:\n",
        "        if tok.isalpha():\n",
        "            suggestions = sym_spell.lookup(tok, Verbosity.CLOSEST, max_edit_distance=2)\n",
        "            corrected_parts.append(suggestions[0].term if suggestions else tok)\n",
        "        else:\n",
        "            corrected_parts.append(tok)\n",
        "    return \"\".join(corrected_parts)\n",
        "\n",
        "# --- 3) Get user input, run correction, measure latency ---\n",
        "try:\n",
        "    user_text = input(\"Enter a sentence to autocorrect: \").strip()\n",
        "except EOFError:\n",
        "    user_text = \"I liek to wrok with pyhton and machne leraning.\"\n",
        "\n",
        "start = time.perf_counter()\n",
        "corrected = autocorrect_sentence(user_text)\n",
        "elapsed_ms = (time.perf_counter() - start) * 1000.0\n",
        "\n",
        "print(\"\\nOriginal : \", user_text)\n",
        "print(\"Corrected: \", corrected)\n",
        "print(f\"Latency  : {elapsed_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-LjXsE_9f-Q",
        "outputId": "864cd936-d6a1-46b8-98e4-0c1e3ca403ff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to autocorrect: thiis ies actwallu veru impresive\n",
            "\n",
            "Original :  thiis ies actwallu veru impresive\n",
            "Corrected:  this is actually very impressive\n",
            "Latency  : 0.97 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hunspell (via spylls, pure-Python)**\n",
        "\n",
        "Hunspell underpins spell-checking in browsers and office suites. It’s morphology-aware (handles affixes, compounds) and very accurate with high-quality dictionaries. Native bindings can be tricky to install, so we’ll use spylls, a pure-Python implementation that loads standard Hunspell dictionaries—portable and suitable for real-time word-level correction."
      ],
      "metadata": {
        "id": "dQZYyomA-ouS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Hunspell (spylls): end-to-end word-based autocorrection with timing (fixed) ===\n",
        "# This cell:\n",
        "# 1) Ensures 'spylls' is installed\n",
        "# 2) Ensures/enables en_US Hunspell dictionary files\n",
        "# 3) Lets you input a sentence\n",
        "# 4) Returns the autocorrected sentence (word-based), preserving punctuation/whitespace\n",
        "# 5) Prints latency\n",
        "\n",
        "import sys, subprocess, os, re, time, urllib.request\n",
        "\n",
        "# --- 1) Ensure dependency is installed ---\n",
        "try:\n",
        "    from spylls.hunspell import Dictionary\n",
        "except Exception:\n",
        "    print(\"Installing 'spylls' (pure-Python Hunspell)...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"spylls\"])\n",
        "    from spylls.hunspell import Dictionary\n",
        "\n",
        "# --- 2) Ensure Hunspell dictionary files are present (en_US) ---\n",
        "DICT_DIR = os.path.join(os.getcwd(), \"hunspell_en_us\")\n",
        "os.makedirs(DICT_DIR, exist_ok=True)\n",
        "AFF_PATH = os.path.join(DICT_DIR, \"en_US.aff\")\n",
        "DIC_PATH = os.path.join(DICT_DIR, \"en_US.dic\")\n",
        "BASE_PATH = os.path.join(DICT_DIR, \"en_US\")\n",
        "\n",
        "if not (os.path.exists(AFF_PATH) and os.path.exists(DIC_PATH)):\n",
        "    print(\"Downloading Hunspell en_US dictionary...\")\n",
        "    aff_url = \"https://cgit.freedesktop.org/libreoffice/dictionaries/plain/en/en_US.aff\"\n",
        "    dic_url = \"https://cgit.freedesktop.org/libreoffice/dictionaries/plain/en/en_US.dic\"\n",
        "    urllib.request.urlretrieve(aff_url, AFF_PATH)\n",
        "    urllib.request.urlretrieve(dic_url, DIC_PATH)\n",
        "\n",
        "# --- 3) Load dictionary ---\n",
        "hun = Dictionary.from_files(BASE_PATH)\n",
        "\n",
        "def hunspell_autocorrect_sentence(sentence: str) -> str:\n",
        "    \"\"\"\n",
        "    Word-based autocorrection using Hunspell (spylls).\n",
        "    - Corrects only alphabetic tokens\n",
        "    - Preserves whitespace/punctuation\n",
        "    - Preserves casing (UPPER/Title/lower) where possible\n",
        "    \"\"\"\n",
        "    def apply_casing(src: str, dst: str) -> str:\n",
        "        if src.isupper():\n",
        "            return dst.upper()\n",
        "        if src.istitle():\n",
        "            return dst.capitalize()\n",
        "        if src.islower():\n",
        "            return dst.lower()\n",
        "        return dst\n",
        "\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]+|\\s+\", sentence)\n",
        "    out = []\n",
        "    for tok in tokens:\n",
        "        if tok.isalpha():\n",
        "            # If known, keep; else pick first suggestion (generator -> next)\n",
        "            known = hun.lookup(tok)\n",
        "            if known:\n",
        "                out.append(tok)\n",
        "            else:\n",
        "                sugg_iter = hun.suggest(tok)\n",
        "                first_suggestion = next(sugg_iter, None)\n",
        "                out.append(apply_casing(tok, first_suggestion) if first_suggestion else tok)\n",
        "        else:\n",
        "            out.append(tok)\n",
        "    return \"\".join(out)\n",
        "\n",
        "# --- 4) Get user input, run correction, measure latency ---\n",
        "try:\n",
        "    user_text = input(\"Enter a sentence to autocorrect: \").strip()\n",
        "except EOFError:\n",
        "    user_text = \"i wnt to go to mu schoul tomorow\"\n",
        "\n",
        "start = time.perf_counter()\n",
        "corrected = hunspell_autocorrect_sentence(user_text)\n",
        "elapsed_ms = (time.perf_counter() - start) * 1000.0\n",
        "\n",
        "print(\"\\nOriginal : \", user_text)\n",
        "print(\"Corrected: \", corrected)\n",
        "print(f\"Latency  : {elapsed_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILvcMM27-qdS",
        "outputId": "32311960-b2dd-420b-d476-5e57d2af55f2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence to autocorrect: i wnt to go to mu schoul tommorrrow\n",
            "\n",
            "Original :  i wnt to go to mu schoul tommorrrow\n",
            "Corrected:  i wt to go to mu school tomorrow\n",
            "Latency  : 198.50 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SymSpell + Left-to-Right Context**\n",
        "\n",
        "\n",
        "This setup keeps SymSpell’s ultra-fast candidate generation but selects the best correction only using past words via a left-to-right scorer. If kenlm is available, we use a compact n-gram LM to score P(word | history_so_far) with a tiny beam search. If kenlm isn’t available, we fall back to a pure-Python bigram backoff trained on a small embedded corpus—still enforcing the “use only previous words” rule."
      ],
      "metadata": {
        "id": "Q_UcHn7hAa5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Left-to-Right Context-Aware Autocorrection (past words only) ===\n",
        "# Uses SymSpell for candidates + LM scorer that sees ONLY previous words.\n",
        "# If 'kenlm' is available, it will be used for scoring; otherwise a tiny\n",
        "# pure-Python bigram backoff model is used as a fallback.\n",
        "#\n",
        "# What this cell does:\n",
        "# 1) Installs symspellpy; tries to install kenlm (optional).\n",
        "# 2) Loads SymSpell dictionary.\n",
        "# 3) Builds a scorer:\n",
        "#       - Preferred: KenLM (if installed)\n",
        "#       - Fallback : Tiny bigram model trained on an embedded mini-corpus\n",
        "# 4) Processes input sentence left->right. For each token:\n",
        "#       - If alphabetic: generate candidates with SymSpell (incl. original)\n",
        "#       - Pick candidate that maximizes LM score given ONLY previous tokens.\n",
        "# 5) Prints corrected sentence and latency (ms).\n",
        "#\n",
        "# Note: This is word-based, preserves punctuation/whitespace, and *never*\n",
        "# looks at future words.\n",
        "\n",
        "import sys, subprocess, os, re, time, math\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Ensure dependencies\n",
        "# -----------------------------\n",
        "try:\n",
        "    from symspellpy import SymSpell, Verbosity\n",
        "except Exception:\n",
        "    print(\"Installing 'symspellpy'...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"symspellpy\"])\n",
        "    from symspellpy import SymSpell, Verbosity\n",
        "\n",
        "# Try kenlm (optional)\n",
        "KENLM_OK = True\n",
        "try:\n",
        "    import kenlm  # type: ignore\n",
        "except Exception:\n",
        "    KENLM_OK = False\n",
        "\n",
        "# -----------------------------\n",
        "# 2) SymSpell dictionary\n",
        "# -----------------------------\n",
        "sym_spell = SymSpell()  # defaults\n",
        "dict_path = \"frequency_dictionary_en_82_765.txt\"\n",
        "if not os.path.exists(dict_path):\n",
        "    import urllib.request\n",
        "    print(\"Downloading SymSpell frequency dictionary...\")\n",
        "    url = \"https://raw.githubusercontent.com/mammothb/symspellpy/master/symspellpy/frequency_dictionary_en_82_765.txt\"\n",
        "    urllib.request.urlretrieve(url, dict_path)\n",
        "\n",
        "sym_spell.load_dictionary(dict_path, term_index=0, count_index=1)\n",
        "\n",
        "# -----------------------------\n",
        "# 3) Scorer(s)\n",
        "# -----------------------------\n",
        "\n",
        "# (A) KenLM scorer (if available). We'll train a tiny model on-the-fly from a mini-corpus\n",
        "# to avoid external files. This is just to enable LM behavior; replace with your own LM binary\n",
        "# for better quality.\n",
        "def _train_tiny_arpa(corpus_text, arpa_path=\"tiny.arpa\", order=3):\n",
        "    \"\"\"\n",
        "    Minimal ARPA generator for demo purposes:\n",
        "    Builds unigram/bigram/trigram with add-k smoothing (k=1e-3) from corpus.\n",
        "    This is *very* small and only for illustration. For production, use a proper\n",
        "    KenLM-built model trained on large text.\n",
        "    \"\"\"\n",
        "    # Tokenize corpus\n",
        "    toks = re.findall(r\"[A-Za-z]+\", corpus_text.lower())\n",
        "    # Add sentence boundaries (roughly)\n",
        "    sents = re.split(r\"[.!?]+\", corpus_text.lower())\n",
        "    sents = [re.findall(r\"[a-z]+\", s) for s in sents if s.strip()]\n",
        "    # Counts\n",
        "    uni = Counter()\n",
        "    bi  = Counter()\n",
        "    tri = Counter()\n",
        "    for s in sents:\n",
        "        prev1 = \"<s>\"\n",
        "        prev2 = None\n",
        "        uni[prev1] += 1\n",
        "        for w in s + [\"</s>\"]:\n",
        "            uni[w] += 1\n",
        "            bi[(prev1, w)] += 1\n",
        "            if prev2 is not None:\n",
        "                tri[(prev2, prev1, w)] += 1\n",
        "            prev2, prev1 = prev1, w\n",
        "    V = len(uni)\n",
        "    k = 1e-3  # tiny smoothing\n",
        "\n",
        "    # Convert to ARPA with stupid backoff-ish logs (not a perfect ARPA; enough for kenlm.load_arpa)\n",
        "    def log10(x):\n",
        "        return -99 if x <= 0 else math.log10(x)\n",
        "\n",
        "    total_unigrams = sum(uni.values())\n",
        "\n",
        "    with open(arpa_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\\\data\\\\\\n\")\n",
        "        f.write(f\"ngram 1={len(uni)}\\n\")\n",
        "        f.write(f\"ngram 2={len(bi)}\\n\")\n",
        "        f.write(f\"ngram 3={len(tri)}\\n\\n\")\n",
        "\n",
        "        # Unigrams\n",
        "        f.write(\"\\\\1-grams:\\n\")\n",
        "        for w, c in uni.items():\n",
        "            p = (c + k) / (total_unigrams + k * V)\n",
        "            f.write(f\"{log10(p):.6f}\\t{w}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "        # Bigrams\n",
        "        f.write(\"\\\\2-grams:\\n\")\n",
        "        prev_totals = defaultdict(int)\n",
        "        for (w1, w2), c in bi.items():\n",
        "            prev_totals[w1] += c\n",
        "        for (w1, w2), c in bi.items():\n",
        "            p = (c + k) / (prev_totals[w1] + k * V)\n",
        "            f.write(f\"{log10(p):.6f}\\t{w1} {w2}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "        # Trigrams\n",
        "        f.write(\"\\\\3-grams:\\n\")\n",
        "        prev2_totals = defaultdict(int)\n",
        "        for (w0, w1, w2), c in tri.items():\n",
        "            prev2_totals[(w0, w1)] += c\n",
        "        for (w0, w1, w2), c in tri.items():\n",
        "            p = (c + k) / (prev2_totals[(w0, w1)] + k * V)\n",
        "            f.write(f\"{log10(p):.6f}\\t{w0} {w1} {w2}\\n\")\n",
        "        f.write(\"\\n\\\\end\\\\\\n\")\n",
        "\n",
        "# Tiny embedded corpus (neutral, handcrafted sentences)\n",
        "TINY_CORPUS = \"\"\"\n",
        "I want to go to school today. I went to school yesterday. I will go to school tomorrow.\n",
        "Which of the two schools do you recommend for tomorrow?\n",
        "I ate an apple today. I like to eat an apple every day.\n",
        "He wants to go to the new school. She went to the old school.\n",
        "\"\"\"\n",
        "\n",
        "KENLM_MODEL = None\n",
        "if KENLM_OK:\n",
        "    try:\n",
        "        if not os.path.exists(\"tiny.arpa\"):\n",
        "            _train_tiny_arpa(TINY_CORPUS, \"tiny.arpa\", order=3)\n",
        "        KENLM_MODEL = kenlm.Model(\"tiny.arpa\")\n",
        "    except Exception as e:\n",
        "        # If kenlm fails to load, disable it and fall back\n",
        "        KENLM_MODEL = None\n",
        "        KENLM_OK = False\n",
        "\n",
        "# (B) Fallback: tiny bigram backoff scorer (pure Python)\n",
        "class TinyBigramLM:\n",
        "    def __init__(self, corpus_text):\n",
        "        sents = [re.findall(r\"[a-z]+\", s) for s in re.split(r\"[.!?]+\", corpus_text.lower()) if s.strip()]\n",
        "        self.uni = Counter()\n",
        "        self.bi  = Counter()\n",
        "        for s in sents:\n",
        "            prev = \"<s>\"\n",
        "            self.uni[prev] += 1\n",
        "            for w in s + [\"</s>\"]:\n",
        "                self.uni[w] += 1\n",
        "                self.bi[(prev, w)] += 1\n",
        "                prev = w\n",
        "        self.V = max(1, len(self.uni))\n",
        "        self.k = 1e-3\n",
        "        self.total_uni = sum(self.uni.values())\n",
        "\n",
        "    def logp(self, history_tokens, word):\n",
        "        # Use only the immediate previous word for context (past-only)\n",
        "        prev = history_tokens[-1] if history_tokens else \"<s>\"\n",
        "        c_bigram = self.bi.get((prev, word), 0)\n",
        "        c_prev   = sum(self.bi.get((prev, w), 0) for w in self.uni.keys())\n",
        "        if c_prev == 0:\n",
        "            # backoff to unigram\n",
        "            p = (self.uni.get(word, 0) + self.k) / (self.total_uni + self.k * self.V)\n",
        "        else:\n",
        "            p = (c_bigram + self.k) / (c_prev + self.k * self.V)\n",
        "        return math.log(p + 1e-12)\n",
        "\n",
        "FALLBACK_LM = TinyBigramLM(TINY_CORPUS)\n",
        "\n",
        "def lm_logp(history_tokens, cand_word):\n",
        "    # Only use past words; never peek ahead.\n",
        "    if KENLM_MODEL is not None:\n",
        "        # Score with KenLM incrementally: join history + candidate\n",
        "        # Using stateful scoring would be faster; for simplicity we recompute per step.\n",
        "        seq = \" \".join([t.lower() for t in history_tokens + [cand_word]])\n",
        "        # kenlm.score returns a log10 probability of the whole sequence + </s> in some builds.\n",
        "        return KENLM_MODEL.score(seq, bos=True, eos=False)\n",
        "    else:\n",
        "        return FALLBACK_LM.logp([t.lower() for t in history_tokens], cand_word.lower())\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Left-to-right correction\n",
        "# -----------------------------\n",
        "def tokenize(sentence):\n",
        "    return re.findall(r\"\\w+|[^\\w\\s]+|\\s+\", sentence)\n",
        "\n",
        "def generate_candidates(word, max_edit_distance=2, keep_original=True, top_k=4):\n",
        "    # SymSpell candidates for the *single* word (not compound). Include original to avoid overcorrection.\n",
        "    cands = []\n",
        "    if keep_original:\n",
        "        cands.append(word)\n",
        "    suggestions = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=max_edit_distance)\n",
        "    for s in suggestions[:top_k]:\n",
        "        if s.term not in cands:\n",
        "            cands.append(s.term)\n",
        "    return cands or [word]\n",
        "\n",
        "def apply_casing(src, dst):\n",
        "    if src.isupper(): return dst.upper()\n",
        "    if src.istitle(): return dst.capitalize()\n",
        "    if src.islower(): return dst.lower()\n",
        "    return dst\n",
        "\n",
        "def correct_left_to_right(text):\n",
        "    tokens = tokenize(text)\n",
        "    history = []        # past corrected words (alphabetic only) for LM\n",
        "    out = []\n",
        "\n",
        "    for tok in tokens:\n",
        "        if tok.isalpha():\n",
        "            cands = generate_candidates(tok)\n",
        "            # Score each candidate using ONLY history (past words)\n",
        "            best = None\n",
        "            best_score = -1e18\n",
        "            for c in cands:\n",
        "                score = lm_logp(history, c)\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best = c\n",
        "            corrected = apply_casing(tok, best)\n",
        "            out.append(corrected)\n",
        "            history.append(corrected)  # update history with corrected word\n",
        "        else:\n",
        "            out.append(tok)            # preserve punctuation/space as-is\n",
        "    return \"\".join(out)\n",
        "\n",
        "# -----------------------------\n",
        "# 5) Run with timing\n",
        "# -----------------------------\n",
        "try:\n",
        "    user_text = input(\"Enter a sentence (past-only context correction): \").strip()\n",
        "except EOFError:\n",
        "    user_text = \"I ate an appel today but I will go to the schol tomorrow.\"\n",
        "\n",
        "start = time.perf_counter()\n",
        "corrected = correct_left_to_right(user_text)\n",
        "elapsed_ms = (time.perf_counter() - start) * 1000.0\n",
        "\n",
        "print(\"\\nOriginal : \", user_text)\n",
        "print(\"Corrected: \", corrected)\n",
        "print(f\"Latency  : {elapsed_ms:.2f} ms\")\n",
        "print(f\"(Scorer: {'KenLM' if KENLM_MODEL is not None else 'Tiny Bigram Fallback'})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45sSJ0LtAl9s",
        "outputId": "47656f97-8ac0-44e4-803e-b80fe0e2f260"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence (past-only context correction): i waant to eet an appel todau\n",
            "\n",
            "Original :  i waant to eet an appel todau\n",
            "Corrected:  i want to eet an appel today\n",
            "Latency  : 0.81 ms\n",
            "(Scorer: Tiny Bigram Fallback)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Benchmark: Five Autocorrection Models on the Same Paragraph ===\n",
        "# Models (must already be initialized from previous cells):\n",
        "# 1) Autocorrect (Python library)          -> expects a global `spell` that is an autocorrect.Speller, or a function\n",
        "# 2) PySpellChecker                        -> expects a global `spell` that is a spellchecker.SpellChecker, or a function\n",
        "# 3) SymSpell (basic, single-word)         -> expects a global `sym_spell` (from symspellpy)\n",
        "# 4) Hunspell via spylls (pure-Python)     -> expects a function `hunspell_autocorrect_sentence`\n",
        "# 5) SymSpell + Left-to-Right Context      -> expects a function `correct_left_to_right`\n",
        "#\n",
        "# What this cell does:\n",
        "# - Defines a LONG paragraph with many spelling mistakes (P_MISSPELLED) and its corrected version (P_CORRECT).\n",
        "# - Invokes each model (without redefining them) to correct the paragraph.\n",
        "# - Measures average correction time per word.\n",
        "# - Compares each output to the correct version (word-level accuracy).\n",
        "#\n",
        "# NOTE:\n",
        "# - This cell **calls** the previously defined objects/functions. If a model wasn't set up,\n",
        "#   it will be marked as \"Unavailable\".\n",
        "# - We avoid rewriting the algorithms; we simply dispatch to already created instances/functions.\n",
        "\n",
        "import re, time, sys\n",
        "\n",
        "# -----------------------------\n",
        "# 0) Test paragraphs\n",
        "# -----------------------------\n",
        "P_MISSPELLED = (\n",
        "    \"Tday I went to the schoul to met with my freinds and discuus the projct. \"\n",
        "    \"We had planed to start earliy, but evryone arived late becuase of the trafic. \"\n",
        "    \"The libary was to noisy, so we moved to a quet classrom. \"\n",
        "    \"I wrote sevral paragraps explaing our ideea, but there were many speling mistaks. \"\n",
        "    \"At lunch, we at sandwhiches and drank cofee while we reviewd the requirments. \"\n",
        "    \"Eventualy, we agredd to updat the timline and asign cleer responsibilites to each person. \"\n",
        "    \"Tomorow, I will send the summery with the corect verion and confirm the scheduel with the instrutor.\"\n",
        ")\n",
        "\n",
        "P_CORRECT = (\n",
        "    \"Today I went to the school to meet with my friends and discuss the project. \"\n",
        "    \"We had planned to start early, but everyone arrived late because of the traffic. \"\n",
        "    \"The library was too noisy, so we moved to a quiet classroom. \"\n",
        "    \"I wrote several paragraphs explaining our idea, but there were many spelling mistakes. \"\n",
        "    \"At lunch, we ate sandwiches and drank coffee while we reviewed the requirements. \"\n",
        "    \"Eventually, we agreed to update the timeline and assign clear responsibilities to each person. \"\n",
        "    \"Tomorrow, I will send the summary with the correct version and confirm the schedule with the instructor.\"\n",
        ")\n",
        "\n",
        "# Helper: tokenize into word tokens (letters only) for accuracy/time-per-word metrics\n",
        "def word_tokens(text):\n",
        "    return re.findall(r\"[A-Za-z]+\", text)\n",
        "\n",
        "def tokenize_preserve(text):\n",
        "    # words, punctuation, spaces — used by some simple callers when needed\n",
        "    return re.findall(r\"\\w+|[^\\w\\s]+|\\s+\", text)\n",
        "\n",
        "TOTAL_WORDS = len(word_tokens(P_MISSPELLED))\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Dispatchers for each model\n",
        "# -----------------------------\n",
        "def run_autocorrect_model(text):\n",
        "    \"\"\"\n",
        "    Autocorrect (Python library).\n",
        "    We assume previous cell created either:\n",
        "      - a global `spell` that is autocorrect.Speller, or\n",
        "      - a function `autocorrect_sentence` that uses autocorrect.Speller under the hood.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from autocorrect import Speller\n",
        "    except Exception:\n",
        "        Speller = None\n",
        "\n",
        "    # Prefer a distinct function if it exists and was defined for Autocorrect\n",
        "    # (We cannot guarantee its name is unique; so we conservatively check the `spell` type.)\n",
        "    if 'spell' in globals() and Speller and isinstance(globals()['spell'], Speller):\n",
        "        s = globals()['spell']\n",
        "        tokens = tokenize_preserve(text)\n",
        "        out = []\n",
        "        for t in tokens:\n",
        "            out.append(s(t) if t.isalpha() else t)\n",
        "        return \"\".join(out)\n",
        "\n",
        "    # Fallback: try a generic `autocorrect_sentence` if available\n",
        "    if 'autocorrect_sentence' in globals():\n",
        "        try:\n",
        "            return globals()['autocorrect_sentence'](text)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    raise RuntimeError(\"Autocorrect model not available (spell/Speller or autocorrect_sentence).\")\n",
        "\n",
        "\n",
        "def run_pyspellchecker_model(text):\n",
        "    \"\"\"\n",
        "    PySpellChecker.\n",
        "    We assume previous cell created either:\n",
        "      - a global `spell` that is spellchecker.SpellChecker, or\n",
        "      - a function `autocorrect_sentence` that uses pyspellchecker under the hood.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from spellchecker import SpellChecker\n",
        "    except Exception:\n",
        "        SpellChecker = None\n",
        "\n",
        "    if 'spell' in globals() and SpellChecker and isinstance(globals()['spell'], SpellChecker):\n",
        "        sc = globals()['spell']\n",
        "        tokens = tokenize_preserve(text)\n",
        "        out = []\n",
        "        for t in tokens:\n",
        "            if t.isalpha():\n",
        "                corr = sc.correction(t)\n",
        "                out.append(corr if corr else t)\n",
        "            else:\n",
        "                out.append(t)\n",
        "        return \"\".join(out)\n",
        "\n",
        "    # Fallback: try a generic `autocorrect_sentence` if available (and hope it's the pyspell version)\n",
        "    if 'autocorrect_sentence' in globals():\n",
        "        try:\n",
        "            return globals()['autocorrect_sentence'](text)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    raise RuntimeError(\"PySpellChecker model not available (spell/SpellChecker or autocorrect_sentence).\")\n",
        "\n",
        "\n",
        "def run_symspell_basic_model(text):\n",
        "    \"\"\"\n",
        "    SymSpell (basic single-word).\n",
        "    We assume a global `sym_spell` from symspellpy is available, as per earlier cell.\n",
        "    We'll call `sym_spell.lookup` per word and pick the closest suggestion.\n",
        "    \"\"\"\n",
        "    if 'sym_spell' not in globals():\n",
        "        raise RuntimeError(\"SymSpell instance `sym_spell` not available.\")\n",
        "    from symspellpy import Verbosity\n",
        "    tokens = tokenize_preserve(text)\n",
        "    out = []\n",
        "    for t in tokens:\n",
        "        if t.isalpha():\n",
        "            suggs = sym_spell.lookup(t, Verbosity.CLOSEST, max_edit_distance=2)\n",
        "            out.append(suggs[0].term if suggs else t)\n",
        "        else:\n",
        "            out.append(t)\n",
        "    return \"\".join(out)\n",
        "\n",
        "\n",
        "def run_hunspell_spylls_model(text):\n",
        "    \"\"\"\n",
        "    Hunspell via spylls (pure-Python).\n",
        "    We assume the earlier cell defined:\n",
        "      - function `hunspell_autocorrect_sentence(text)` which performs the correction.\n",
        "    \"\"\"\n",
        "    if 'hunspell_autocorrect_sentence' not in globals():\n",
        "        raise RuntimeError(\"Hunspell function `hunspell_autocorrect_sentence` not available.\")\n",
        "    return hunspell_autocorrect_sentence(text)\n",
        "\n",
        "\n",
        "def run_symspell_left2right_model(text):\n",
        "    \"\"\"\n",
        "    SymSpell + Left-to-Right Context (past-only).\n",
        "    We assume the earlier cell defined:\n",
        "      - function `correct_left_to_right(text)`.\n",
        "    \"\"\"\n",
        "    if 'correct_left_to_right' not in globals():\n",
        "        raise RuntimeError(\"Left-to-Right function `correct_left_to_right` not available.\")\n",
        "    return correct_left_to_right(text)\n",
        "\n",
        "# -----------------------------\n",
        "# 2) Benchmark runner\n",
        "# -----------------------------\n",
        "def avg_time_per_word_seconds(func, text):\n",
        "    start = time.perf_counter()\n",
        "    out = func(text)\n",
        "    total = time.perf_counter() - start\n",
        "    return out, total / max(1, TOTAL_WORDS)\n",
        "\n",
        "def word_accuracy(pred_text, gold_text):\n",
        "    pred = word_tokens(pred_text)\n",
        "    gold = word_tokens(gold_text)\n",
        "    # Align by position (simple exact-match rate). If lengths differ, compare over min length.\n",
        "    n = min(len(pred), len(gold))\n",
        "    if n == 0:\n",
        "        return 0.0\n",
        "    correct = sum(1 for i in range(n) if pred[i].lower() == gold[i].lower())\n",
        "    return 100.0 * correct / len(gold)\n",
        "\n",
        "# -----------------------------\n",
        "# 3) Execute and report\n",
        "# -----------------------------\n",
        "results = []\n",
        "\n",
        "models = [\n",
        "    (\"Autocorrect (Python library)\", run_autocorrect_model),\n",
        "    (\"PySpellChecker\",               run_pyspellchecker_model),\n",
        "    (\"SymSpell (basic)\",             run_symspell_basic_model),\n",
        "    (\"Hunspell (spylls)\",            run_hunspell_spylls_model),\n",
        "    (\"SymSpell + Left-to-Right\",     run_symspell_left2right_model),\n",
        "]\n",
        "\n",
        "print(\"=== Original (Misspelled) Paragraph ===\")\n",
        "print(P_MISSPELLED, \"\\n\")\n",
        "print(\"=== Correct (Reference) Paragraph ===\")\n",
        "print(P_CORRECT, \"\\n\")\n",
        "\n",
        "for name, runner in models:\n",
        "    try:\n",
        "        output, avg_sec_per_word = avg_time_per_word_seconds(runner, P_MISSPELLED)\n",
        "        acc = word_accuracy(output, P_CORRECT)\n",
        "        results.append((name, f\"{avg_sec_per_word*1000:.3f} ms/word\", f\"{acc:.1f}%\"))\n",
        "        print(f\"\\n--- {name} ---\")\n",
        "        print(output)\n",
        "        print(f\"[Avg time/word] {avg_sec_per_word*1000:.3f} ms | [Word accuracy vs. reference] {acc:.1f}%\")\n",
        "    except Exception as e:\n",
        "        results.append((name, \"Unavailable\", \"N/A\"))\n",
        "        print(f\"\\n--- {name} ---\")\n",
        "        print(f\"Unavailable: {e}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Summary table\n",
        "# -----------------------------\n",
        "print(\"\\n=== Summary (Avg Time Per Word & Word Accuracy) ===\")\n",
        "colw = [28, 18, 18]\n",
        "print(f\"{'Model':{colw[0]}} {'Avg Time/Word':{colw[1]}} {'Word Accuracy':{colw[2]}}\")\n",
        "print(\"-\" * sum(colw))\n",
        "for name, timepw, acc in results:\n",
        "    print(f\"{name:{colw[0]}} {timepw:{colw[1]}} {acc:{colw[2]}}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqi6qDjdB2Y8",
        "outputId": "0d482d11-e120-4887-b2a6-d552e6249581"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Original (Misspelled) Paragraph ===\n",
            "Tday I went to the schoul to met with my freinds and discuus the projct. We had planed to start earliy, but evryone arived late becuase of the trafic. The libary was to noisy, so we moved to a quet classrom. I wrote sevral paragraps explaing our ideea, but there were many speling mistaks. At lunch, we at sandwhiches and drank cofee while we reviewd the requirments. Eventualy, we agredd to updat the timline and asign cleer responsibilites to each person. Tomorow, I will send the summery with the corect verion and confirm the scheduel with the instrutor. \n",
            "\n",
            "=== Correct (Reference) Paragraph ===\n",
            "Today I went to the school to meet with my friends and discuss the project. We had planned to start early, but everyone arrived late because of the traffic. The library was too noisy, so we moved to a quiet classroom. I wrote several paragraphs explaining our idea, but there were many spelling mistakes. At lunch, we ate sandwiches and drank coffee while we reviewed the requirements. Eventually, we agreed to update the timeline and assign clear responsibilities to each person. Tomorrow, I will send the summary with the correct version and confirm the schedule with the instructor. \n",
            "\n",
            "\n",
            "--- Autocorrect (Python library) ---\n",
            "day a went to the school to met with my friends and discuss the project. be had planed to start early, but everyone arrived late because of the traffic. the library was to noisy, so we moved to a que classroom. a wrote several paragraph explain our idea, but there were many spelling mistake. it lunch, we at sandwiches and drank coffee while we review the requirements. eventually, we agreed to update the timeline and sign clear responsibilities to each person. tomorrow, a will send the summery with the correct version and confirm the schedule with the instructor.\n",
            "[Avg time/word] 0.115 ms | [Word accuracy vs. reference] 82.7%\n",
            "\n",
            "--- PySpellChecker ---\n",
            "day I went to the school to met with my friends and discuss the project. We had planed to start early, but everyone arrived late because of the traffic. The library was to noisy, so we moved to a quiet classroom. I wrote several paragraph explain our idea, but there were many spelling mistake. At lunch, we at sandwiches and drank coffee while we review the requirements. eventually, we agreed to update the timeline and sign clear responsibilities to each person. tomorrow, I will send the summery with the correct version and confirm the schedule with the instructor.\n",
            "[Avg time/word] 1.037 ms | [Word accuracy vs. reference] 88.8%\n",
            "\n",
            "--- SymSpell (basic) ---\n",
            "day a went to the school to met with my friends and discuss the project. be had planed to start early, but everyone arrived late because of the traffic. the library was to noisy, so we moved to a que classroom. a wrote several paragraph explain our idea, but there were many spelling mistake. it lunch, we at sandwiches and drank coffee while we review the requirements. eventually, we agreed to update the timeline and sign clear responsibilities to each person. tomorrow, a will send the summery with the correct version and confirm the schedule with the instructor.\n",
            "[Avg time/word] 0.033 ms | [Word accuracy vs. reference] 82.7%\n",
            "\n",
            "--- Hunspell (spylls) ---\n",
            "Day I went to the school to met with my friends and discus the project. We had planed to start early, but everyone rived late because of the tragic. The library was to noisy, so we moved to a wet classroom. I wrote several paragraphs explain our idea, but there were many spieling mistakes. At lunch, we at sandwiches and drank coffee while we reviews the requirements. Eventual, we agreed to update the timeline and sign creel responsibilities to each person. Tomorrow, I will send the summery with the correct version and confirm the schedule with the instructor.\n",
            "[Avg time/word] 4.500 ms | [Word accuracy vs. reference] 83.7%\n",
            "\n",
            "--- SymSpell + Left-to-Right ---\n",
            "Tday I went to the schoul to met with my freinds and discuus the projct. He had planed to start earliy, but evryone arived late becuase of the trafic. The libary was to noisy, so we moved to a quet classrom. I wrote sevral paragraps explaing our ideea, but there were many speling mistaks. At lunch, we at sandwhiches and drank cofee while we reviewd the requirments. Eventualy, we agredd to updat the timline and asign cleer responsibilites to each person. Tomorrow, I will send the summery with the corect verion and confirm the scheduel with the instrutor.\n",
            "[Avg time/word] 0.528 ms | [Word accuracy vs. reference] 59.2%\n",
            "\n",
            "=== Summary (Avg Time Per Word & Word Accuracy) ===\n",
            "Model                        Avg Time/Word      Word Accuracy     \n",
            "----------------------------------------------------------------\n",
            "Autocorrect (Python library) 0.115 ms/word      82.7%             \n",
            "PySpellChecker               1.037 ms/word      88.8%             \n",
            "SymSpell (basic)             0.033 ms/word      82.7%             \n",
            "Hunspell (spylls)            4.500 ms/word      83.7%             \n",
            "SymSpell + Left-to-Right     0.528 ms/word      59.2%             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Benchmark (Round 2): Longer Paragraph with More Typos ===\n",
        "# Assumes the following were already defined in previous cells:\n",
        "#   - Autocorrect model: either global `spell` (autocorrect.Speller) or function `autocorrect_sentence`\n",
        "#   - PySpellChecker model: either global `spell` (spellchecker.SpellChecker) or function `autocorrect_sentence`\n",
        "#   - SymSpell instance: global `sym_spell`\n",
        "#   - Hunspell (spylls): function `hunspell_autocorrect_sentence(text)`\n",
        "#   - SymSpell + Left-to-Right Context: function `correct_left_to_right(text)`\n",
        "#\n",
        "# This cell:\n",
        "#   1) Defines a LONGER misspelled paragraph and its corrected reference version.\n",
        "#   2) Calls EACH model (without redefining them) to correct the paragraph.\n",
        "#   3) Measures average correction time per word and word-level accuracy vs. reference.\n",
        "#\n",
        "# If any model hasn’t been initialized, it will be marked “Unavailable”.\n",
        "\n",
        "import re, time\n",
        "\n",
        "# -----------------------------\n",
        "# 0) Longer test paragraphs\n",
        "# -----------------------------\n",
        "P_MISSPELLED = (\n",
        "    \"Yesturday mornng, I desided to wake up earli and take a quick walke to the libary, \"\n",
        "    \"but the weathr was unpredicteble and it strated to rain hevily. On my way, I met two freinds \"\n",
        "    \"who were also planing to study, yet we all relized we had fogoten our noteboks and pencials. \"\n",
        "    \"At the coffe shop nerby, we ordred sandwitches and capachinos, but the barrista misspeled my \"\n",
        "    \"name on the cup as Alxenderr, which made us laught for a whiel. When we finaly arived at the \"\n",
        "    \"libary, it was overcrowded and very noizy, so we searched for a quiter clasroom in the oldr \"\n",
        "    \"building. I began writting a draft of our reseach propasal, explaing the metodolgy and the \"\n",
        "    \"expreimental desgin, but I kept makng speling mistkes becuse I was in a hurry. My freinds \"\n",
        "    \"sugested we take a brek and reorgnize the timline, asign clerer resposnibilites, and setup \"\n",
        "    \"a sharedd calender. Tomorow, we inted to meet agan with the instrutor to reveiw the feedbak, \"\n",
        "    \"corect the erors, and submitt the finel versoin befor the dedline at midnigt.\"\n",
        ")\n",
        "\n",
        "P_CORRECT = (\n",
        "    \"Yesterday morning, I decided to wake up early and take a quick walk to the library, \"\n",
        "    \"but the weather was unpredictable and it started to rain heavily. On my way, I met two friends \"\n",
        "    \"who were also planning to study, yet we all realized we had forgotten our notebooks and pencils. \"\n",
        "    \"At the coffee shop nearby, we ordered sandwiches and cappuccinos, but the barista misspelled my \"\n",
        "    \"name on the cup as Alexander, which made us laugh for a while. When we finally arrived at the \"\n",
        "    \"library, it was overcrowded and very noisy, so we searched for a quieter classroom in the older \"\n",
        "    \"building. I began writing a draft of our research proposal, explaining the methodology and the \"\n",
        "    \"experimental design, but I kept making spelling mistakes because I was in a hurry. My friends \"\n",
        "    \"suggested we take a break and reorganize the timeline, assign clearer responsibilities, and set up \"\n",
        "    \"a shared calendar. Tomorrow, we intend to meet again with the instructor to review the feedback, \"\n",
        "    \"correct the errors, and submit the final version before the deadline at midnight.\"\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers (no model code here)\n",
        "# -----------------------------\n",
        "def word_tokens(text):\n",
        "    return re.findall(r\"[A-Za-z]+\", text)\n",
        "\n",
        "def tokenize_preserve(text):\n",
        "    return re.findall(r\"\\w+|[^\\w\\s]+|\\s+\", text)\n",
        "\n",
        "TOTAL_WORDS = len(word_tokens(P_MISSPELLED))\n",
        "\n",
        "def avg_time_per_word_seconds(func, text):\n",
        "    start = time.perf_counter()\n",
        "    out = func(text)\n",
        "    total = time.perf_counter() - start\n",
        "    return out, total / max(1, TOTAL_WORDS)\n",
        "\n",
        "def word_accuracy(pred_text, gold_text):\n",
        "    pred = word_tokens(pred_text)\n",
        "    gold = word_tokens(gold_text)\n",
        "    n = min(len(pred), len(gold))\n",
        "    if n == 0:\n",
        "        return 0.0\n",
        "    correct = sum(1 for i in range(n) if pred[i].lower() == gold[i].lower())\n",
        "    return 100.0 * correct / len(gold)\n",
        "\n",
        "# -----------------------------\n",
        "# Dispatchers (call-only)\n",
        "# -----------------------------\n",
        "def run_autocorrect_model(text):\n",
        "    try:\n",
        "        from autocorrect import Speller\n",
        "    except Exception:\n",
        "        Speller = None\n",
        "\n",
        "    if 'spell' in globals() and Speller and isinstance(globals()['spell'], Speller):\n",
        "        s = globals()['spell']\n",
        "        tokens = tokenize_preserve(text)\n",
        "        return \"\".join([s(t) if t.isalpha() else t for t in tokens])\n",
        "\n",
        "    if 'autocorrect_sentence' in globals():\n",
        "        return globals()['autocorrect_sentence'](text)\n",
        "\n",
        "    raise RuntimeError(\"Autocorrect model not available.\")\n",
        "\n",
        "\n",
        "def run_pyspellchecker_model(text):\n",
        "    try:\n",
        "        from spellchecker import SpellChecker\n",
        "    except Exception:\n",
        "        SpellChecker = None\n",
        "\n",
        "    if 'spell' in globals() and SpellChecker and isinstance(globals()['spell'], SpellChecker):\n",
        "        sc = globals()['spell']\n",
        "        out = []\n",
        "        for t in tokenize_preserve(text):\n",
        "            if t.isalpha():\n",
        "                corr = sc.correction(t)\n",
        "                out.append(corr if corr else t)\n",
        "            else:\n",
        "                out.append(t)\n",
        "        return \"\".join(out)\n",
        "\n",
        "    if 'autocorrect_sentence' in globals():\n",
        "        return globals()['autocorrect_sentence'](text)\n",
        "\n",
        "    raise RuntimeError(\"PySpellChecker model not available.\")\n",
        "\n",
        "\n",
        "def run_symspell_basic_model(text):\n",
        "    if 'sym_spell' not in globals():\n",
        "        raise RuntimeError(\"SymSpell instance `sym_spell` not available.\")\n",
        "    from symspellpy import Verbosity\n",
        "    out = []\n",
        "    for t in tokenize_preserve(text):\n",
        "        if t.isalpha():\n",
        "            suggs = sym_spell.lookup(t, Verbosity.CLOSEST, max_edit_distance=2)\n",
        "            out.append(suggs[0].term if suggs else t)\n",
        "        else:\n",
        "            out.append(t)\n",
        "    return \"\".join(out)\n",
        "\n",
        "\n",
        "def run_hunspell_spylls_model(text):\n",
        "    if 'hunspell_autocorrect_sentence' not in globals():\n",
        "        raise RuntimeError(\"Hunspell function `hunspell_autocorrect_sentence` not available.\")\n",
        "    return hunspell_autocorrect_sentence(text)\n",
        "\n",
        "\n",
        "def run_symspell_left2right_model(text):\n",
        "    if 'correct_left_to_right' not in globals():\n",
        "        raise RuntimeError(\"Left-to-Right function `correct_left_to_right` not available.\")\n",
        "    return correct_left_to_right(text)\n",
        "\n",
        "# -----------------------------\n",
        "# Execute & report\n",
        "# -----------------------------\n",
        "print(\"=== Original (Misspelled) Paragraph ===\")\n",
        "print(P_MISSPELLED, \"\\n\")\n",
        "print(\"=== Correct (Reference) Paragraph ===\")\n",
        "print(P_CORRECT, \"\\n\")\n",
        "\n",
        "results = []\n",
        "models = [\n",
        "    (\"Autocorrect (Python library)\", run_autocorrect_model),\n",
        "    (\"PySpellChecker\",               run_pyspellchecker_model),\n",
        "    (\"SymSpell (basic)\",             run_symspell_basic_model),\n",
        "    (\"Hunspell (spylls)\",            run_hunspell_spylls_model),\n",
        "    (\"SymSpell + Left-to-Right\",     run_symspell_left2right_model),\n",
        "]\n",
        "\n",
        "for name, runner in models:\n",
        "    try:\n",
        "        output, avg_sec_per_word = avg_time_per_word_seconds(runner, P_MISSPELLED)\n",
        "        acc = word_accuracy(output, P_CORRECT)\n",
        "        results.append((name, f\"{avg_sec_per_word*1000:.3f} ms/word\", f\"{acc:.1f}%\"))\n",
        "        print(f\"\\n--- {name} ---\")\n",
        "        print(output)\n",
        "        print(f\"[Avg time/word] {avg_sec_per_word*1000:.3f} ms | [Word accuracy vs. reference] {acc:.1f}%\")\n",
        "    except Exception as e:\n",
        "        results.append((name, \"Unavailable\", \"N/A\"))\n",
        "        print(f\"\\n--- {name} ---\")\n",
        "        print(f\"Unavailable: {e}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Summary table\n",
        "# -----------------------------\n",
        "print(\"\\n=== Summary (Avg Time Per Word & Word Accuracy) ===\")\n",
        "colw = [28, 18, 18]\n",
        "print(f\"{'Model':{colw[0]}} {'Avg Time/Word':{colw[1]}} {'Word Accuracy':{colw[2]}}\")\n",
        "print(\"-\" * sum(colw))\n",
        "for name, timepw, acc in results:\n",
        "    print(f\"{name:{colw[0]}} {timepw:{colw[1]}} {acc:{colw[2]}}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGGYmRRfCWOt",
        "outputId": "3e6acfe7-dd70-4500-8fbd-5acba3d7d1a1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Original (Misspelled) Paragraph ===\n",
            "Yesturday mornng, I desided to wake up earli and take a quick walke to the libary, but the weathr was unpredicteble and it strated to rain hevily. On my way, I met two freinds who were also planing to study, yet we all relized we had fogoten our noteboks and pencials. At the coffe shop nerby, we ordred sandwitches and capachinos, but the barrista misspeled my name on the cup as Alxenderr, which made us laught for a whiel. When we finaly arived at the libary, it was overcrowded and very noizy, so we searched for a quiter clasroom in the oldr building. I began writting a draft of our reseach propasal, explaing the metodolgy and the expreimental desgin, but I kept makng speling mistkes becuse I was in a hurry. My freinds sugested we take a brek and reorgnize the timline, asign clerer resposnibilites, and setup a sharedd calender. Tomorow, we inted to meet agan with the instrutor to reveiw the feedbak, corect the erors, and submitt the finel versoin befor the dedline at midnigt. \n",
            "\n",
            "=== Correct (Reference) Paragraph ===\n",
            "Yesterday morning, I decided to wake up early and take a quick walk to the library, but the weather was unpredictable and it started to rain heavily. On my way, I met two friends who were also planning to study, yet we all realized we had forgotten our notebooks and pencils. At the coffee shop nearby, we ordered sandwiches and cappuccinos, but the barista misspelled my name on the cup as Alexander, which made us laugh for a while. When we finally arrived at the library, it was overcrowded and very noisy, so we searched for a quieter classroom in the older building. I began writing a draft of our research proposal, explaining the methodology and the experimental design, but I kept making spelling mistakes because I was in a hurry. My friends suggested we take a break and reorganize the timeline, assign clearer responsibilities, and set up a shared calendar. Tomorrow, we intend to meet again with the instructor to review the feedback, correct the errors, and submit the final version before the deadline at midnight. \n",
            "\n",
            "\n",
            "--- Autocorrect (Python library) ---\n",
            "yesterday morning, a decided to wake up early and take a quick walk to the library, but the weather was unpredictable and it started to rain heavily. in my way, a met two friends who were also planing to study, yet we all realized we had forgotten our notebooks and pencils. it the coffee shop nearby, we ordered sandwiches and capuchins, but the barista misspelled my name on the cup as Alxenderr, which made us caught for a while. when we final arrived at the library, it was overcrowded and very noisy, so we searched for a quite classroom in the old building. a began writing a draft of our research proposal, explain the methodology and the experimental design, but a kept making spelling mistakes because a was in a hurry. by friends suggested we take a break and reorganize the timeline, sign clever responsibilities, and setup a shared calender. tomorrow, we intel to meet again with the instructor to review the feedback, correct the errors, and submit the final version before the deadline at midnight.\n",
            "[Avg time/word] 0.047 ms | [Word accuracy vs. reference] 72.3%\n",
            "\n",
            "--- PySpellChecker ---\n",
            "yesterday morning, I decided to wake up early and take a quick walk to the library, but the weather was unpredictable and it started to rain heavily. On my way, I met two friends who were also planing to study, yet we all realized we had forgotten our notebooks and pencils. At the coffee shop nearby, we ordered sandwiches and capuchins, but the barrister misspelled my name on the cup as Alxenderr, which made us caught for a while. When we finally arrived at the library, it was overcrowded and very noisy, so we searched for a quite classroom in the old building. I began writing a draft of our research proposal, explain the methodology and the experimental design, but I kept making spelling mistakes because I was in a hurry. My friends suggested we take a break and reorganize the timeline, sign clever responsibilities, and setup a shared calender. tomorrow, we intend to meet again with the instructor to review the feedback, correct the errors, and submit the fine version before the deadline at midnight.\n",
            "[Avg time/word] 33.263 ms | [Word accuracy vs. reference] 76.8%\n",
            "\n",
            "--- SymSpell (basic) ---\n",
            "yesterday morning, a decided to wake up early and take a quick walk to the library, but the weather was unpredictable and it started to rain heavily. in my way, a met two friends who were also planing to study, yet we all realized we had forgotten our notebooks and pencils. it the coffee shop nearby, we ordered sandwiches and capuchins, but the barista misspelled my name on the cup as Alxenderr, which made us caught for a while. when we final arrived at the library, it was overcrowded and very noisy, so we searched for a quite classroom in the old building. a began writing a draft of our research proposal, explain the methodology and the experimental design, but a kept making spelling mistakes because a was in a hurry. by friends suggested we take a break and reorganize the timeline, sign clever responsibilities, and setup a shared calender. tomorrow, we intel to meet again with the instructor to review the feedback, correct the errors, and submit the final version before the deadline at midnight.\n",
            "[Avg time/word] 0.036 ms | [Word accuracy vs. reference] 72.3%\n",
            "\n",
            "--- Hunspell (spylls) ---\n",
            "Yesterday morning, I desired to wake up earl and take a quick wake to the library, but the weather was unpredictable and it started to rain heavily. On my way, I met two friends who were also planing to study, yet we all relied we had forgotten our notebooks and pencils. At the coffee shop nervy, we ordered sandwiches and cappuccinos, but the barista misspelled my name on the cup as Alexander, which made us aught for a while. When we final rived at the library, it was overcrowded and very noisy, so we searched for a quite classroom in the lord building. I began witting a draft of our research proposal, explain the methodology and the experimental design, but I kept making spieling mistakes because I was in a hurry. My friends suggested we take a berk and reorganize the timeline, sign clearer responsibility, and setup a shared calendar. Tomorrow, we intend to meet again with the instructor to review the feedback, correct the errs, and submit the fine version before the deadline at midnight.\n",
            "[Avg time/word] 5.543 ms | [Word accuracy vs. reference] 72.9%\n",
            "\n",
            "--- SymSpell + Left-to-Right ---\n",
            "Yesturday mornng, I desided to wake up earli and take a quick walke to the libary, but the weathr was unpredicteble and it strated to rain hevily. An my way, I met two freinds who were also planing to study, yet we all relized we had fogoten our noteboks and pencials. At the coffe shop nerby, we ordred sandwitches and capachinos, but the barrista misspeled my name on the cup as Alxenderr, which made us laught for a whiel. When we finaly arived at the libary, it was overcrowded and very noizy, so we searched for a quiter clasroom in the old building. I began writting a draft of our reseach propasal, explaing the metodolgy and the expreimental desgin, but I kept makng speling mistkes becuse I was in a hurry. My freinds sugested we take a brek and reorgnize the timline, asign clerer resposnibilites, and setup a sharedd calender. Tomorrow, we inted to meet agan with the instrutor to reveiw the feedbak, corect the erors, and submitt the finel versoin befor the dedline at midnigt.\n",
            "[Avg time/word] 0.052 ms | [Word accuracy vs. reference] 52.5%\n",
            "\n",
            "=== Summary (Avg Time Per Word & Word Accuracy) ===\n",
            "Model                        Avg Time/Word      Word Accuracy     \n",
            "----------------------------------------------------------------\n",
            "Autocorrect (Python library) 0.047 ms/word      72.3%             \n",
            "PySpellChecker               33.263 ms/word     76.8%             \n",
            "SymSpell (basic)             0.036 ms/word      72.3%             \n",
            "Hunspell (spylls)            5.543 ms/word      72.9%             \n",
            "SymSpell + Left-to-Right     0.052 ms/word      52.5%             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Final Benchmark: Evaluate ONLY on Misspelled Words ===\n",
        "# Assumes the following models are already set up in previous cells and callable:\n",
        "#   - Autocorrect (Python library):        run_autocorrect_model(text)\n",
        "#   - PySpellChecker:                      run_pyspellchecker_model(text)\n",
        "#   - SymSpell (basic):                    run_symspell_basic_model(text)\n",
        "#   - Hunspell (spylls):                   run_hunspell_spylls_model(text)\n",
        "#   - SymSpell + Left-to-Right Context:    run_symspell_left2right_model(text)\n",
        "#\n",
        "# This cell:\n",
        "#   1) Defines a test paragraph (misspelled) and its corrected reference.\n",
        "#   2) Identifies positions of words that are misspelled (compared to reference).\n",
        "#   3) Runs each model and computes accuracy ONLY over those misspelled positions.\n",
        "#   4) Reports average time per *misspelled* word (latency divided by #misspelled words).\n",
        "\n",
        "import re, time\n",
        "\n",
        "# -----------------------------\n",
        "# 0) Test paragraph (reuse the \"common sentences\" set for realistic phrasing)\n",
        "# -----------------------------\n",
        "P_MISSPELLED = (\n",
        "    \"I tolld my frend how are you afer we went to scool. \"\n",
        "    \"I didnt recieve your emial yesturday, can you resent it agan? \"\n",
        "    \"We are going to the libary later to finsh our homwork. \"\n",
        "    \"The wethar was relly nice so we walkd to the coffe shop nearbly. \"\n",
        "    \"She said she wil call me tomorow morning befor class. \"\n",
        "    \"I bought vegtables and bred from the grocry store on my way home. \"\n",
        "    \"Please chekc the sheduele and let me no if your free on Thusday. \"\n",
        "    \"After luch we met the instrutor to discus the projeckt detales. \"\n",
        "    \"He allways forgets his pasword and needs to resset it evry weak. \"\n",
        "    \"Thanks for your help, I appriciate your quick responce.\"\n",
        ")\n",
        "\n",
        "P_CORRECT = (\n",
        "    \"I told my friend how are you after we went to school. \"\n",
        "    \"I didn’t receive your email yesterday, can you resend it again? \"\n",
        "    \"We are going to the library later to finish our homework. \"\n",
        "    \"The weather was really nice so we walked to the coffee shop nearby. \"\n",
        "    \"She said she will call me tomorrow morning before class. \"\n",
        "    \"I bought vegetables and bread from the grocery store on my way home. \"\n",
        "    \"Please check the schedule and let me know if you’re free on Thursday. \"\n",
        "    \"After lunch we met the instructor to discuss the project details. \"\n",
        "    \"He always forgets his password and needs to reset it every week. \"\n",
        "    \"Thanks for your help, I appreciate your quick response.\"\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def word_tokens(text):\n",
        "    # normalize typographic apostrophes to plain for alignment fairness\n",
        "    text = text.replace(\"’\", \"'\")\n",
        "    return re.findall(r\"[A-Za-z']+\", text)\n",
        "\n",
        "def indices_of_misspellings(src_text, gold_text):\n",
        "    src = word_tokens(src_text)\n",
        "    gold = word_tokens(gold_text)\n",
        "    n = min(len(src), len(gold))\n",
        "    idxs = [i for i in range(n) if src[i].lower() != gold[i].lower()]\n",
        "    return idxs, src, gold\n",
        "\n",
        "def accuracy_on_indices(pred_text, gold_words, idxs):\n",
        "    pred = word_tokens(pred_text)\n",
        "    n = min(len(pred), len(gold_words), (max(idxs) + 1) if idxs else 0)\n",
        "    if not idxs:\n",
        "        return 100.0\n",
        "    correct = 0\n",
        "    for i in idxs:\n",
        "        if i < n and pred[i].lower() == gold_words[i].lower():\n",
        "            correct += 1\n",
        "    return 100.0 * correct / len(idxs)\n",
        "\n",
        "def avg_time_per_target_word_seconds(func, text, n_targets):\n",
        "    start = time.perf_counter()\n",
        "    out = func(text)\n",
        "    total = time.perf_counter() - start\n",
        "    denom = max(1, n_targets)\n",
        "    return out, total / denom\n",
        "\n",
        "# -----------------------------\n",
        "# Validate availability of model runners\n",
        "# -----------------------------\n",
        "required = [\n",
        "    (\"Autocorrect (Python library)\", \"run_autocorrect_model\"),\n",
        "    (\"PySpellChecker\",               \"run_pyspellchecker_model\"),\n",
        "    (\"SymSpell (basic)\",             \"run_symspell_basic_model\"),\n",
        "    (\"Hunspell (spylls)\",            \"run_hunspell_spylls_model\"),\n",
        "    (\"SymSpell + Left-to-Right\",     \"run_symspell_left2right_model\"),\n",
        "]\n",
        "missing = [name for name, fn in required if fn not in globals()]\n",
        "if missing:\n",
        "    print(\"WARNING: The following models are not available and will be marked Unavailable:\")\n",
        "    for m in missing: print(\" -\", m)\n",
        "\n",
        "# -----------------------------\n",
        "# Compute misspelled indices once\n",
        "# -----------------------------\n",
        "miss_idx, src_words, gold_words = indices_of_misspellings(P_MISSPELLED, P_CORRECT)\n",
        "N_MISS = len(miss_idx)\n",
        "print(f\"Detected {N_MISS} misspelled word positions (evaluating only these).\")\n",
        "\n",
        "# -----------------------------\n",
        "# Run each model on misspell-only metric\n",
        "# -----------------------------\n",
        "def get_runner(name, fn_name):\n",
        "    return globals()[fn_name] if fn_name in globals() else None\n",
        "\n",
        "models = [\n",
        "    (\"Autocorrect (Python library)\", get_runner(\"Autocorrect (Python library)\", \"run_autocorrect_model\")),\n",
        "    (\"PySpellChecker\",               get_runner(\"PySpellChecker\",               \"run_pyspellchecker_model\")),\n",
        "    (\"SymSpell (basic)\",             get_runner(\"SymSpell (basic)\",             \"run_symspell_basic_model\")),\n",
        "    (\"Hunspell (spylls)\",            get_runner(\"Hunspell (spylls)\",            \"run_hunspell_spylls_model\")),\n",
        "    (\"SymSpell + Left-to-Right\",     get_runner(\"SymSpell + Left-to-Right\",     \"run_symspell_left2right_model\")),\n",
        "]\n",
        "\n",
        "results = []\n",
        "for name, runner in models:\n",
        "    if runner is None:\n",
        "        results.append((name, \"Unavailable\", \"N/A\"))\n",
        "        print(f\"\\n--- {name} ---\\nUnavailable: runner not found.\")\n",
        "        continue\n",
        "    try:\n",
        "        output, avg_sec_per_miss = avg_time_per_target_word_seconds(runner, P_MISSPELLED, N_MISS)\n",
        "        acc = accuracy_on_indices(output, gold_words, miss_idx)\n",
        "        results.append((name, f\"{avg_sec_per_miss*1000:.3f} ms/misspelled-word\", f\"{acc:.1f}%\"))\n",
        "        print(f\"\\n--- {name} ---\")\n",
        "        print(output)\n",
        "        print(f\"[Avg time per misspelled word] {avg_sec_per_miss*1000:.3f} ms | \"\n",
        "              f\"[Accuracy on misspelled words] {acc:.1f}%\")\n",
        "    except Exception as e:\n",
        "        results.append((name, \"Unavailable\", \"N/A\"))\n",
        "        print(f\"\\n--- {name} ---\\nUnavailable: {e}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Summary\n",
        "# -----------------------------\n",
        "print(\"\\n=== Summary (Avg Time Per Misspelled Word & Accuracy on Misspelled Words) ===\")\n",
        "colw = [28, 30, 26]\n",
        "print(f\"{'Model':{colw[0]}} {'Avg Time/Misspelled Word':{colw[1]}} {'Accuracy (Misspelled Only)':{colw[2]}}\")\n",
        "print(\"-\" * sum(colw))\n",
        "for name, timepw, acc in results:\n",
        "    print(f\"{name:{colw[0]}} {timepw:{colw[1]}} {acc:{colw[2]}}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2qu_EJ3Dbdy",
        "outputId": "28ddd446-4230-4aa5-c9d6-5cb200187fba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 41 misspelled word positions (evaluating only these).\n",
            "\n",
            "--- Autocorrect (Python library) ---\n",
            "a told my friend how are you after we went to school. a didst receive your email yesterday, can you resent it again? be are going to the library later to fish our homework. the wether was reply nice so we walk to the coffee shop nearly. the said she will call me tomorrow morning before class. a bought vegetables and bred from the grocery store on my way home. please check the schedule and let me no if your free on thursday. after such we met the instructor to discus the project details. be always forgets his password and needs to reset it very weak. thanks for your help, a appreciate your quick response.\n",
            "[Avg time per misspelled word] 0.271 ms | [Accuracy on misspelled words] 65.9%\n",
            "\n",
            "--- PySpellChecker ---\n",
            "I told my friend how are you after we went to school. I didn't receive your email yesterday, can you resent it again? We are going to the library later to finish our homework. The wether was really nice so we walk to the coffee shop nearly. She said she will call me tomorrow morning before class. I bought vegetables and bred from the grocery store on my way home. Please check the schedule and let me no if your free on thursday. After much we met the instructor to discus the project details. He always forgets his password and needs to reset it very weak. Thanks for your help, I appreciate your quick response.\n",
            "[Avg time per misspelled word] 33.137 ms | [Accuracy on misspelled words] 73.2%\n",
            "\n",
            "--- SymSpell (basic) ---\n",
            "a told my friend how are you after we went to school. a didst receive your email yesterday, can you resent it again? be are going to the library later to fish our homework. the wether was reply nice so we walk to the coffee shop nearly. the said she will call me tomorrow morning before class. a bought vegetables and bred from the grocery store on my way home. please check the schedule and let me no if your free on thursday. after such we met the instructor to discus the project details. be always forgets his password and needs to reset it very weak. thanks for your help, a appreciate your quick response.\n",
            "[Avg time per misspelled word] 0.075 ms | [Accuracy on misspelled words] 65.9%\n",
            "\n",
            "--- Hunspell (spylls) ---\n",
            "I tolls my rend how are you fare we went to cool. I dint receive your email yesterday, can you resent it again? We are going to the library later to fish our homework. The wetware was telly nice so we walks to the coffee shop nearly. She said she wile call me tomorrow morning before class. I bought vegetables and bred from the grocery store on my way home. Please check the scheduled and let me no if your free on Thursday. After lute we met the instructor to discus the project tattletales. He always forgets his password and needs to reset it very weak. Thanks for your help, I appreciate your quick response.\n",
            "[Avg time per misspelled word] 12.449 ms | [Accuracy on misspelled words] 48.8%\n",
            "\n",
            "--- SymSpell + Left-to-Right ---\n",
            "I tolld my frend how are you afer we went to school. I didnt recieve your emial yesterday, can you resent it agan? He are going to the libary later to finsh our homwork. The wethar was relly nice so we walkd to the coffe shop nearbly. The said she wil call me tomorrow morning befor class. I bought vegtables and bred from the grocry store on my way home. Please chekc the sheduele and let me no if your free on Thusday. After luch we met the instrutor to discus the projeckt detales. He allways forgets his pasword and needs to resset it every weak. Thanks for your help, I appriciate your quick responce.\n",
            "[Avg time per misspelled word] 0.147 ms | [Accuracy on misspelled words] 9.8%\n",
            "\n",
            "=== Summary (Avg Time Per Misspelled Word & Accuracy on Misspelled Words) ===\n",
            "Model                        Avg Time/Misspelled Word       Accuracy (Misspelled Only)\n",
            "------------------------------------------------------------------------------------\n",
            "Autocorrect (Python library) 0.271 ms/misspelled-word       65.9%                     \n",
            "PySpellChecker               33.137 ms/misspelled-word      73.2%                     \n",
            "SymSpell (basic)             0.075 ms/misspelled-word       65.9%                     \n",
            "Hunspell (spylls)            12.449 ms/misspelled-word      48.8%                     \n",
            "SymSpell + Left-to-Right     0.147 ms/misspelled-word       9.8%                      \n"
          ]
        }
      ]
    }
  ]
}