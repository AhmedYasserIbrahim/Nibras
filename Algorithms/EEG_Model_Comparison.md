
# Descriptive Comparison of Classification Models for Motor Imagery EEG

| **Model Type**        | **Model**               | **Pros**                                                 | **Cons**                                                   | **Typical Use Case**                          | **Implementation Notes**                                                                 |
|-----------------------|-------------------------|----------------------------------------------------------|------------------------------------------------------------|------------------------------------------------|--------------------------------------------------------------------------------------------|
| **Traditional ML**    | **SVM**                 | Good with small datasets, robust decision boundaries     | Needs manual feature extraction, struggles with >2 classes | Early testing and benchmarking                | Extract features (e.g., band power, CSP), then train SVM using `scikit-learn`              |
|                       | **Random Forest**       | Handles noisy data, easy to interpret                    | Less accurate for EEG vs DL models                         | Fast prototyping with structured features      | Use preprocessed features (e.g., means, variances), train using `scikit-learn`             |
|                       | **KNN**                 | Simple, no training time                                 | Slow prediction, sensitive to scaling                      | Educational or baseline comparison             | Extract features, normalize, then apply `KNN` via `scikit-learn`                           |
| **Deep Learning**     | **EEGNet (Compact CNN)**| Lightweight, made for EEG, good accuracy                 | Less flexible than larger CNNs                             | Best balance of accuracy & efficiency          | Use raw/filtered EEG as 2D input (channels Ã— time), implement with `TensorFlow` or `PyTorch` |
|                       | **ShallowConvNet**      | Simple, interpretable filters                           | May underperform on complex signals                        | Real-time classification with few resources    | Similar to EEGNet but fewer layers; suited for fast testing                                 |
|                       | **DeepConvNet**         | Higher accuracy, more layers                             | Heavy computation, risk of overfitting                     | Large, high-quality datasets                   | Use full CNN stacks to extract temporal + spatial features                                  |
| **Recurrent Models**  | **LSTM / GRU**          | Captures time dependencies                               | Needs a lot of data, training is slow                      | Temporal modeling of sequential EEG data       | Use after CNN layer to model time across signals; `Keras` or `PyTorch`                     |
| **Hybrid Models**     | **CNN + RNN**           | Learns spatial + temporal features                       | Complex to tune, requires more data                        | High-accuracy systems                          | Stack CNN layers for feature extraction + RNN layers for sequence modeling                  |
|                       | **CNN + Attention**     | Focuses on key signal regions, high accuracy             | Computationally heavy                                      | Advanced, real-time prediction systems         | Add attention layers after CNN to focus on most informative EEG regions                     |
